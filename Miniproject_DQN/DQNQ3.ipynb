{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement the dqn for me using pytorch and openai gym\n",
    "import matplotlib.pyplot as plt\n",
    "from gym import spaces\n",
    "\n",
    "\"\"\"Environment imports\"\"\"\n",
    "from epidemic_env.env       import Env, Log\n",
    "from epidemic_env.dynamics  import ModelDynamics, Observation\n",
    "from epidemic_env.visualize import Visualize\n",
    "from epidemic_env.agent     import Agent\n",
    "\n",
    "\"\"\"Pytorch and numpy imports\"\"\"\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "%matplotlib inline\n",
    "dyn = ModelDynamics('config/switzerland.yaml')   # load the switzerland map\n",
    "\n",
    "# get the cuda\n",
    "# import optimimzer\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import math\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "from IPython import display\n",
    "from torch.autograd import Variable\n",
    "from collections import deque\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(DQN, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_dim, 64)\n",
    "        self.linear2 = nn.Linear(64, 32)\n",
    "        self.linear3 = nn.Linear(32, 16)\n",
    "        self.linear4 = nn.Linear(16, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.linear1(x))\n",
    "        x = torch.relu(self.linear2(x)) \n",
    "        x = torch.relu(self.linear3(x))\n",
    "        return self.linear3(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sampled action : 1\n",
      "Sampled observation\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 288x370.286 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "action_space        =   spaces.Discrete(2)\n",
    "observation_space   =   spaces.Box( low=0,\n",
    "                                    high=1,\n",
    "                                    shape=(2, dyn.n_cities, dyn.env_step_length),\n",
    "                                    dtype=np.float16)\n",
    "print(f\"sampled action : {action_space.sample()}\")\n",
    "print(\"Sampled observation\")\n",
    "plt.matshow(observation_space.sample()[1,:,:])\n",
    "plt.show()\n",
    "\n",
    "SCALE = 100\n",
    "ACTION_NULL = 0\n",
    "ACTION_CONFINE = 1\n",
    "ACTION_ISOLATE = 2\n",
    "ACTION_HOSPITAL = 3\n",
    "ACTION_VACCINATE = 4\n",
    "\n",
    "\n",
    "def action_preprocessor(a:torch.Tensor, dyn:ModelDynamics):\n",
    "    action = { \n",
    "        'confinement': False, \n",
    "        'isolation': False, \n",
    "        'hospital': False, \n",
    "        'vaccinate': False,\n",
    "    }\n",
    "    \n",
    "    if a == ACTION_CONFINE:\n",
    "        action['confinement'] = True\n",
    "    elif a == ACTION_ISOLATE:\n",
    "        action['isolation'] = True\n",
    "    elif a == ACTION_VACCINATE:\n",
    "        action['vaccinate'] = True\n",
    "    elif a == ACTION_HOSPITAL:\n",
    "        action['hospital'] = True\n",
    "        \n",
    "    return action\n",
    "    \n",
    "def observation_preprocessor(obs: Observation, dyn:ModelDynamics):\n",
    "    infected = SCALE * np.power(np.array([np.array(obs.city[c].infected)/obs.pop[c] for c in dyn.cities]), 0.25)\n",
    "    dead = SCALE * np.power( np.array([np.array(obs.city[c].dead)/obs.pop[c] for c in dyn.cities]), 0.25)\n",
    "    confined = np.ones_like(dead)*int((dyn.get_action()['confinement']))\n",
    "    return torch.Tensor(np.stack((infected, dead, confined))).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Env(  dyn,\n",
    "            action_space=action_space,\n",
    "            observation_space=observation_space,\n",
    "            action_preprocessor=action_preprocessor,\n",
    "            observation_preprocessor=observation_preprocessor,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN_Agent(Agent):\n",
    "    def __init__(self,  env:Env,\n",
    "                # Additionnal parameters to be added here\n",
    "                ):\n",
    "        super(DQN_Agent, self).__init__(env)\n",
    "        self.env = env\n",
    "        \n",
    "    def load_model(self, savepath):\n",
    "        # This is where one would define the routine for loading a pre-trained model\n",
    "        pass\n",
    "\n",
    "    def save_model(self, savepath):\n",
    "        # This is where one would define the routine for saving the weights for a trained model\n",
    "        pass\n",
    "\n",
    "    def optimize_model(self):\n",
    "        # This is where one would define the optimization step of an RL algorithm\n",
    "        return 0\n",
    "    \n",
    "    def reset(self,):\n",
    "        # This should be called when the environment is reset\n",
    "        pass\n",
    "    \n",
    "    def act(self, obs):\n",
    "        # this takes an observation and returns an action\n",
    "        # the action space can be directly sampled from the env\n",
    "        return self.env.action_space.sample() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device}\")\n",
    "\n",
    "BATCH_SIZE = 2048\n",
    "GAMMA = 0.9\n",
    "LR = 5e-3\n",
    "\n",
    "# Get number of actions from gym action space\n",
    "# n_actions = env.action_space.n\n",
    "# Get the number of state observations\n",
    "state, info = env.reset(42)\n",
    "n_observations = len(state)\n",
    "\n",
    "\n",
    "policy_net = DQN(n_observations, 2).to(device)\n",
    "target_net = DQN(n_observations, 2).to(device)\n",
    "\n",
    "target_net.load_state_dict(policy_net.state_dict()) \n",
    "\n",
    "optimizer = optim.AdamW(policy_net.parameters(), lr=LR, amsgrad=True)\n",
    "memory = ReplayMemory(10000) \n",
    "\n",
    "\n",
    "steps_done = 0\n",
    "\n",
    "\n",
    "def select_action(state):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "        math.exp(-1. * steps_done / EPS_DECAY)\n",
    "    steps_done += 1\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            # t.max(1) will return the largest column value of each row.\n",
    "            # second column on max result is index of where max element was\n",
    "            # found, so we pick action with the larger expected reward.\n",
    "            return policy_net(state).max(1)[1].view(1, 1)\n",
    "    else:\n",
    "        return torch.tensor([[env.action_space.sample()]], device=device, dtype=torch.long)\n",
    "\n",
    "\n",
    "episode_durations = []\n",
    "\n",
    "\n",
    "def plot_durations(show_result=False):\n",
    "    plt.figure(1)\n",
    "    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
    "    if show_result:\n",
    "        plt.title('Result')\n",
    "    else:\n",
    "        plt.clf()\n",
    "        plt.title('Training...')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Duration')\n",
    "    plt.plot(durations_t.numpy())\n",
    "    # Take 100 episode averages and plot them too\n",
    "    if len(durations_t) >= 100:\n",
    "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
    "        means = torch.cat((torch.zeros(99), means))\n",
    "        plt.plot(means.numpy())\n",
    "\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "    if is_ipython:\n",
    "        if not show_result:\n",
    "            display.display(plt.gcf())\n",
    "            display.clear_output(wait=True)\n",
    "        else:\n",
    "            display.display(plt.gcf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
